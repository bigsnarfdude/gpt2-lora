{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b",
   "metadata": {
    "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b"
   },
   "source": [
    "<font size=\"1\">\n",
    "Supplementary code for \"Build a Large Language Model From Scratch\": <a href=\"https://www.manning.com/books/build-a-large-language-model-from-scratch\">https://www.manning.com/books/build-a-large-language-model-from-scratch</a> by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8c870-fb72-490e-8916-d8129bd5d1ff",
   "metadata": {
    "id": "58b8c870-fb72-490e-8916-d8129bd5d1ff"
   },
   "source": [
    "# Appendix E: Parameter-efficient Finetuning with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
    "outputId": "316166b4-027a-4756-e9b4-fe88ae75dd4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.8.4\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.6.0\n",
      "torch version: 2.2.1\n",
      "tensorflow version: 2.16.1\n",
      "pandas version: 2.2.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\", # For OpenAI's pretrained weights\n",
    "        \"pandas\"      # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21532056-0ef4-4c98-82c7-e91f61c6485e",
   "metadata": {
    "id": "21532056-0ef4-4c98-82c7-e91f61c6485e"
   },
   "source": [
    "## E.1 Introduction to LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66edc999-3d91-4a1c-a157-9d056392e8d8",
   "metadata": {
    "id": "66edc999-3d91-4a1c-a157-9d056392e8d8"
   },
   "source": [
    "- No code in this section\n",
    "- Low-rank adaptation (LoRA) is a machine learning technique that modifies a pretrained model to better suit a specific, often smaller, dataset by adjusting only a small, low-rank subset of the model's parameters\n",
    "- This approach is important because it allows for efficient finetuning of large models on task-specific data, significantly reducing the computational cost and time required for finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb75b5d-d59c-4948-821a-1594a5883dc1",
   "metadata": {
    "id": "5bb75b5d-d59c-4948-821a-1594a5883dc1"
   },
   "source": [
    "- Suppose we have a large weight matrix $W$ for a given layer\n",
    "- During backpropagation, we learn a $\\Delta W$ matrix, which contains information on how much we want to update the original weights to minimize the loss function during training\n",
    "- In regular training and finetuning, the weight update is defined as follows:\n",
    "\n",
    "$$W_{\\text{updated}} = W + \\Delta W$$\n",
    "\n",
    "- The LoRA method proposed by [Hu et al.](https://arxiv.org/abs/2106.09685) offers a more efficient alternative to computing the weight updates $\\Delta W$ by learning an approximation of it, $\\Delta W \\approx AB$.\n",
    "- In other words, in LoRA, we have the following, where $A$ and $B$ are two small weight matrices:\n",
    "\n",
    "$$W_{\\text{updated}} = W + AB$$\n",
    "\n",
    "- The figure below illustrates these formulas for full finetuning and LoRA side by side"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7419d-cae9-4525-bb44-1641f6ef4f3b",
   "metadata": {
    "id": "a8a7419d-cae9-4525-bb44-1641f6ef4f3b"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-1.webp\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edd43c9-8ec5-48e6-b3fc-5fb3c16037cc",
   "metadata": {
    "id": "4edd43c9-8ec5-48e6-b3fc-5fb3c16037cc"
   },
   "source": [
    "- If you paid close attention, the full finetuning and LoRA depictions in the figure above look slightly different from the formulas I have shown earlier\n",
    "- That's due to the distributive law of matrix multiplication: we don't have to add the weights with the updated weights but can keep them separate\n",
    "- For instance, if $x$ is the input data, then we can write the following for regular finetuning:\n",
    "\n",
    "$$x (W+\\Delta W) = x W + x \\Delta W$$\n",
    "\n",
    "- Similarly, we can write the following for LoRA:\n",
    "\n",
    "$$x (W+A B) = x W + x A B$$\n",
    "\n",
    "- The fact that we can keep the LoRA weight matrices separate makes LoRA especially attractive\n",
    "- In practice, this means that we don't have to modify the weights of the pretrained model at all, as we can apply the LoRA matrices on the fly\n",
    "- After setting up the dataset and loading the model, we will implement LoRA in the code to make these concepts less abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
   "metadata": {
    "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
   },
   "source": [
    "## E.2 Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c64df-4431-4d27-834d-2bb38a01fc02",
   "metadata": {
    "id": "669c64df-4431-4d27-834d-2bb38a01fc02"
   },
   "source": [
    "- This section repeats the code from chapter 6 to load and prepare the dataset\n",
    "- Instead of repeating this code, one could open and run the chapter 6 notebook and then insert the LoRA code from section E.4 there\n",
    "- (The LoRA code was originally the last section of chapter 6 but was moved to the appendix due to the length of chapter 6)\n",
    "- In a similar fashion, we could also apply LoRA to the models in chapter 7 for instruction finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
    "outputId": "a67a7afe-b401-4463-c731-87025d20f72d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from previous_chapters import (\n",
    "    download_and_unzip_spam_data,\n",
    "    create_balanced_dataset,\n",
    "    random_split\n",
    ")\n",
    "\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import tiktoken\n",
    "from previous_chapters import SpamDataset\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "train_dataset = SpamDataset(\"train.csv\", max_length=None, tokenizer=tokenizer)\n",
    "val_dataset = SpamDataset(\"validation.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
    "test_dataset = SpamDataset(\"test.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
   "metadata": {
    "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57"
   },
   "source": [
    "- As a verification step, we iterate through the data loaders and check that the batches contain 8 training examples each, where each training example consists of 120 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
    "outputId": "2ae34de1-dd01-4f99-d2c8-ba4dca400754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
   "metadata": {
    "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1"
   },
   "source": [
    "- Lastly, let's print the total number of batches in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "4d19ed61-cf7a-4ec4-b822-c847dd1c5d77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec9aa4a-ffd2-4d9f-a835-cce1059fe604",
   "metadata": {
    "id": "dec9aa4a-ffd2-4d9f-a835-cce1059fe604"
   },
   "source": [
    "## E.3 Initializing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36ebdaf-810e-46a2-9ad9-e017a04051b1",
   "metadata": {
    "id": "f36ebdaf-810e-46a2-9ad9-e017a04051b1"
   },
   "source": [
    "- This section repeats the code from chapter 6 to load and prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02b3a506-3879-4258-82b5-93a5b6bafa74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02b3a506-3879-4258-82b5-93a5b6bafa74",
    "outputId": "b8c9b125-bb52-45d3-8071-fa5054dbf5a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 05:01:22.022651: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-24 05:01:22.217235: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-24 05:01:22.702699: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "checkpoint: 100%|███████████████████████████| 77.0/77.0 [00:00<00:00, 83.0kiB/s]\n",
      "encoder.json: 100%|███████████████████████| 1.04M/1.04M [00:00<00:00, 3.28MiB/s]\n",
      "hparams.json: 100%|██████████████████████████| 90.0/90.0 [00:00<00:00, 221kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|███████| 498M/498M [00:58<00:00, 8.53MiB/s]\n",
      "model.ckpt.index: 100%|███████████████████| 5.21k/5.21k [00:00<00:00, 5.18MiB/s]\n",
      "model.ckpt.meta: 100%|██████████████████████| 471k/471k [00:00<00:00, 2.09MiB/s]\n",
      "vocab.bpe: 100%|████████████████████████████| 456k/456k [00:00<00:00, 2.02MiB/s]\n"
     ]
    }
   ],
   "source": [
    "from get_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252614cd-7ce6-4908-83e6-3761f519904e",
   "metadata": {
    "id": "252614cd-7ce6-4908-83e6-3761f519904e"
   },
   "source": [
    "- To ensure that the model was loaded corrected, let's double-check that it generates coherent text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b6ce20c-0700-4783-8be0-4cf17c200a7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8b6ce20c-0700-4783-8be0-4cf17c200a7f",
    "outputId": "28ccbca5-8de9-41a0-c093-da00fcbaa91c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8174b31b-1ab5-4115-b01c-245369da5af3",
   "metadata": {
    "id": "8174b31b-1ab5-4115-b01c-245369da5af3"
   },
   "source": [
    "- Then, we prepare the model for classification finetuning similar to chapter 6, where we replace the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e255ce91-d73a-4854-90a4-95804928eb16",
   "metadata": {
    "id": "e255ce91-d73a-4854-90a4-95804928eb16"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=768, out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02e6f057-1383-4ece-8444-0a88e71ac75d",
   "metadata": {
    "id": "02e6f057-1383-4ece-8444-0a88e71ac75d"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device);  # no assignment model = model.to(device) necessary for nn.Module classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e951cd6-5e42-44d2-b21f-895cb61004fe",
   "metadata": {
    "id": "8e951cd6-5e42-44d2-b21f-895cb61004fe"
   },
   "source": [
    "- Lastly, let's calculate the initial classification accuracy of the non-finetuned model (we expect this to be around 50%, which means that the model is not able to distinguish between spam and non-spam messages yet reliably)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc7dd72c-73a2-4881-ade0-0a9605f1ab8c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fc7dd72c-73a2-4881-ade0-0a9605f1ab8c",
    "outputId": "74848515-5a49-4125-fecb-9f4bac23f812"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import calc_accuracy_loader\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398a1ec9-e2a1-43d6-bf9f-12ee54b46a7b",
   "metadata": {
    "id": "398a1ec9-e2a1-43d6-bf9f-12ee54b46a7b"
   },
   "source": [
    "## E.4 Parameter-efficient finetuning with LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a4a82-61ef-4d0a-9858-8988e844f12c",
   "metadata": {
    "id": "652a4a82-61ef-4d0a-9858-8988e844f12c"
   },
   "source": [
    "- We begin by initializing a LoRALayer that creates the matrices $A$ and $B$, along with the `alpha` scaling hyperparameter and the `rank` ($r$) hyperparameters\n",
    "- This layer can accept an input and compute the corresponding output, as illustrated in the figure below\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-2.webp\" width=\"200px\">\n",
    "\n",
    "In code, this LoRA layer depicted in the figure above looks like as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ds9ywjMwvIW",
   "metadata": {
    "id": "2ds9ywjMwvIW"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class LoRALayer(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
    "        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))  # similar to standard weight initialization\n",
    "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.alpha * (x @ self.A @ self.B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad21faa8-0614-4257-93cd-68952193e14a",
   "metadata": {
    "id": "ad21faa8-0614-4257-93cd-68952193e14a"
   },
   "source": [
    "- In the code above, `rank` is a hyperparameter that controls the inner dimension of the matrices $A$ and $B$\n",
    "- In other words, this parameter controls the number of additional parameters introduced by LoRA and is a key factor in determining the balance between model adaptability and parameter efficiency\n",
    "- The second hyperparameter, `alpha`, is a scaling hyperparameter applied to the output of the low-rank adaptation\n",
    "- It essentially controls the extent to which the adapted layer's output is allowed to influence the original output of the layer being adapted\n",
    "- This can be seen as a way to regulate the impact of the low-rank adaptation on the layer's output\n",
    "- So far, the `LoRALayer` class we implemented above allows us to transform the layer inputs $x$\n",
    "- However, in LoRA, we are usually interested in replacing existing `Linear` layers so that the weight update is applied to the existing pretrained weights, as shown in the figure below\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-3.webp\" width=\"200px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d5da0-dfce-4808-b89b-29ff333f563f",
   "metadata": {
    "id": "3e6d5da0-dfce-4808-b89b-29ff333f563f"
   },
   "source": [
    "- To incorporate the original `Linear` layer weights as shown in the figure above, we implement a `LinearWithLoRA` layer below that uses the previously implemented LoRALayer and can be used to replace existing `Linear` layers in a neural network, for example, the self-attention module or feed forward modules in an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "127d3a64-8359-4b21-b056-78d58cc75fe8",
   "metadata": {
    "id": "127d3a64-8359-4b21-b056-78d58cc75fe8"
   },
   "outputs": [],
   "source": [
    "class LinearWithLoRA(torch.nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.lora = LoRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x) + self.lora(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1145a90-35ff-462c-820b-15483fa5b051",
   "metadata": {
    "id": "e1145a90-35ff-462c-820b-15483fa5b051"
   },
   "source": [
    "- Note that since we initialize the weight matrix $B$ (`self.B` in `LoRALayer`) with zero values in the LoRA layer, the matrix multiplication between $A$ and $B$ results in a matrix consisting of 0's and doesn't affect the original weights (since adding 0 to the original weights does not modify them)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98a6d36-7bc9-434c-a7f1-533f26aff06d",
   "metadata": {
    "id": "e98a6d36-7bc9-434c-a7f1-533f26aff06d"
   },
   "source": [
    "- To try LoRA on the GPT model we defined earlier, we define a `replace_linear_with_lora` function to replace all `Linear` layers in the model with the new `LinearWithLoRA` layers\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-4.webp\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "WlQZ8ygqzN_g",
   "metadata": {
    "id": "WlQZ8ygqzN_g"
   },
   "outputs": [],
   "source": [
    "def replace_linear_with_lora(model, rank, alpha):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            # Replace the Linear layer with LinearWithLoRA\n",
    "            setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
    "        else:\n",
    "            # Recursively apply the same function to child modules\n",
    "            replace_linear_with_lora(module, rank, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c172164-cdde-4489-b7d7-aaed9cc2f5f2",
   "metadata": {
    "id": "8c172164-cdde-4489-b7d7-aaed9cc2f5f2"
   },
   "source": [
    "- We then freeze the original model parameter and use the `replace_linear_with_lora` to replace the said `Linear` layers using the code below\n",
    "- This will replace the `Linear` layers in the LLM with `LinearWithLoRA` layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbe15350-4da9-4829-9d23-98bbd3d0b1a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbe15350-4da9-4829-9d23-98bbd3d0b1a1",
    "outputId": "fd4c208f-854a-4701-d9d3-9d73af733364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters before: 124,441,346\n",
      "Total trainable parameters after: 0\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters before: {total_params:,}\")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters after: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "mLk_fPq0yz_u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLk_fPq0yz_u",
    "outputId": "0a93b8fc-05d7-4ace-ee47-e2fc6bdd7d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable LoRA parameters: 2,666,528\n"
     ]
    }
   ],
   "source": [
    "replace_linear_with_lora(model, rank=16, alpha=16)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable LoRA parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6819e-ef7a-4f0d-841a-1b467496bef9",
   "metadata": {
    "id": "b8b6819e-ef7a-4f0d-841a-1b467496bef9"
   },
   "source": [
    "- As we can see, we reduced the number of trainable parameters by almost 50x when using LoRA\n",
    "- Let's now double-check whether the layers have been modified as intended by printing the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1711be61-bb2c-466f-9b5b-24f4aa5ccd9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1711be61-bb2c-466f-9b5b-24f4aa5ccd9c",
    "outputId": "acff8eca-3775-45a2-b62d-032a986ef037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): LinearWithLoRA(\n",
      "    (linear): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (lora): LoRALayer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bbc9d7-65ec-4675-bab8-2e56eb0cfb55",
   "metadata": {
    "id": "c4bbc9d7-65ec-4675-bab8-2e56eb0cfb55"
   },
   "source": [
    "- Based on the model architecture above, we can see that the model now contains our new `LinearWithLoRA` layers\n",
    "- Also, since we initialized matrix $B$ with 0's, we expect the initial model performance to be unchanged compared to before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "DAlrb_I00VEU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DAlrb_I00VEU",
    "outputId": "3da44ac4-230b-4358-d996-30b63f0d962a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13735b3e-f0c3-4dba-ae3d-4141b2878101",
   "metadata": {
    "id": "13735b3e-f0c3-4dba-ae3d-4141b2878101"
   },
   "source": [
    "- Let's now get to the interesting part and finetune the model by reusing the training function from chapter 6\n",
    "- The training takes about 15 minutes on a M3 MacBook Air laptop computer and less than half a minute on a V100 or A100 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "wCParRvr0eff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCParRvr0eff",
    "outputId": "ce910a9c-ee89-48bb-bfa6-49c6aee1e450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 0.010, Val loss 0.203\n",
      "Ep 1 (Step 000050): Train loss 0.000, Val loss 0.459\n",
      "Ep 1 (Step 000100): Train loss 0.000, Val loss 0.315\n",
      "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
      "Ep 2 (Step 000150): Train loss 0.000, Val loss 0.509\n",
      "Ep 2 (Step 000200): Train loss 0.000, Val loss 0.071\n",
      "Ep 2 (Step 000250): Train loss 0.018, Val loss 0.064\n",
      "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
      "Ep 3 (Step 000300): Train loss 0.000, Val loss 0.133\n",
      "Ep 3 (Step 000350): Train loss 0.000, Val loss 0.070\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 4 (Step 000400): Train loss 0.000, Val loss 0.104\n",
      "Ep 4 (Step 000450): Train loss 0.000, Val loss 0.102\n",
      "Ep 4 (Step 000500): Train loss 0.000, Val loss 0.101\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.000, Val loss 0.101\n",
      "Ep 5 (Step 000600): Train loss 0.000, Val loss 0.102\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 0.39 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from previous_chapters import train_classifier_simple\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c89e82-3aa8-44c6-b046-0b16200b8e6c",
   "metadata": {
    "id": "d0c89e82-3aa8-44c6-b046-0b16200b8e6c"
   },
   "source": [
    "- Finally, let's evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bawWGijA0iF3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "bawWGijA0iF3",
    "outputId": "af70782a-d605-4376-fa6c-d33b38979cfa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAEiCAYAAAA21pHjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABPUElEQVR4nO3deXhTVfrA8e9N0qT7TjdKC0gBgZatLAVElF1lRHRQhkFwHZRFBh03ZHVBx0HRYWQER9BxARHxh4oMiywqIGuh0FJRlrbQhUL3JW2S+/sjbUooS1takpb38zz3SXJz7s2b0zRvzrnn3qOoqqoihBBCCKekcXQAQgghhLg8SdRCCCGEE5NELYQQQjgxSdRCCCGEE5NELYQQQjgxSdRCCCGEE5NELYQQQjgxSdRCCCGEE5NELYQQQjgxSdRCCDsDBgxg2rRpjg5DCFFBErUQ9WzChAkoilJtGTZsmKNDE0I0QjpHByBEUzRs2DCWLVtmt85gMDgoGiFEYyYtaiEagMFgICQkxG7x8/MDYOvWrej1en788Udb+QULFhAYGEh6ejoA69evp1+/fvj6+hIQEMBdd93F77//bit/8uRJFEXhiy++4JZbbsHNzY0ePXrw66+/smfPHmJjY/H09GTYsGGcPXvWtt2ECRMYOXIkc+fOJSgoCG9vb/7yl79QVlZ22fdSVlbGs88+S/PmzfHw8KBXr15s3brV9vypU6cYMWIEfn5+eHh40LFjR9atW3fZ/b333ntERUXh6upKcHAw9913n+05VVX5+9//TuvWrXFzc6Nz5858+eWXdtsnJiZyxx134OnpSXBwMOPGjSM7O9v2/IABA5g6dSrPPvss/v7+hISEMGfOnMvGI4Szk0QtxHVWeQx43Lhx5OXlcfDgQWbMmMHSpUsJDQ0FoKioiOnTp7Nnzx42b96MRqPhnnvuwWKx2O1r9uzZvPTSS+zfvx+dTseYMWN49tlneeedd/jxxx/5/fffmTVrlt02mzdvJikpiS1btvD555+zZs0a5s6de9l4H3roIX7++WdWrFjBoUOH+OMf/8iwYcM4duwYAJMmTcJoNLJ9+3YSEhJ444038PT0vOS+9u7dy9SpU5k3bx7JycmsX7+e/v37255/6aWXWLZsGYsXL+bIkSP89a9/5c9//jPbtm0DID09nVtvvZUuXbqwd+9e1q9fT2ZmJqNHj7Z7nY8++ggPDw9++eUX/v73vzNv3jw2btxYw7+QEE5GFULUq/Hjx6tarVb18PCwW+bNm2crYzQa1a5du6qjR49WO3bsqD766KNX3GdWVpYKqAkJCaqqquqJEydUQP3ggw9sZT7//HMVUDdv3mxbN3/+fLVdu3Z2sfn7+6tFRUW2dYsXL1Y9PT1Vs9msqqqq3nrrrepTTz2lqqqq/vbbb6qiKOrp06ft4hk4cKD6wgsvqKqqqtHR0eqcOXNqVDerV69Wvb291fz8/GrPFRYWqq6uruqOHTvs1j/yyCPqmDFjVFVV1ZkzZ6pDhgyxez41NVUF1OTkZFv8/fr1syvTo0cP9bnnnqtRjEI4GzlGLUQDuO2221i8eLHdOn9/f9t9vV7PJ598QkxMDJGRkSxcuNCu7O+//87MmTPZtWsX2dnZtpZ0SkoKnTp1spWLiYmx3Q8ODgYgOjrabl1WVpbdvjt37oy7u7vtcVxcHIWFhaSmphIZGWlXdv/+/aiqStu2be3WG41GAgICAJg6dSpPPPEEGzZsYNCgQdx77712cV1o8ODBREZG0rp1a4YNG8awYcO45557cHd3JzExkdLSUgYPHmy3TVlZGV27dgVg3759bNmy5ZIt9t9//90W58WvHxoaWq0ehGgsJFEL0QA8PDxo06bNFcvs2LEDgPPnz3P+/Hk8PDxsz40YMYIWLVqwdOlSwsLCsFgsdOrUqdqxZBcXF9t9RVEuue7i7vLLqdz+QhaLBa1Wy759+9BqtXbPVSbLRx99lKFDh/Ldd9+xYcMG5s+fz4IFC5gyZUq1/Xl5ebF//362bt3Khg0bmDVrFnPmzGHPnj22OL/77juaN29ut13lQDyLxcKIESN44403qu278rDBxXVQ+d5qWg9COBtJ1EI4wO+//85f//pXli5dyhdffMGDDz5oOxZ97tw5kpKSeP/997nlllsA+Omnn+rttQ8ePEhJSQlubm4A7Nq1C09PT8LDw6uV7dq1K2azmaysLFssl9KiRQsmTpzIxIkTeeGFF1i6dOklEzWATqdj0KBBDBo0iNmzZ+Pr68sPP/zA4MGDMRgMpKSkcOutt15y227durF69WpatmyJTidfX+LGIJ90IRqA0WgkIyPDbp1OpyMwMBCz2cy4ceMYMmQIDz30EMOHDyc6OpoFCxbwt7/9DT8/PwICAliyZAmhoaGkpKTw/PPP11tsZWVlPPLII7z00kucOnWK2bNnM3nyZDSa6mNL27Zty9ixY3nwwQdZsGABXbt2JTs7mx9++IHo6GjuuOMOpk2bxvDhw2nbti05OTn88MMP3HzzzZd87W+//Zbjx4/Tv39//Pz8WLduHRaLhXbt2uHl5cUzzzzDX//6VywWC/369SM/P58dO3bg6enJ+PHjmTRpEkuXLmXMmDH87W9/IzAwkN9++40VK1awdOnSaq1+IZoCSdRCNID169fbdcUCtGvXjqNHj/Lqq69y8uRJvvnmGwBCQkL44IMPGD16NIMHD6ZLly6sWLGCqVOn0qlTJ9q1a8e7777LgAED6iW2gQMHEhUVRf/+/TEajTzwwANXPH1p2bJlvPLKKzz99NOcPn2agIAA4uLiuOOOOwAwm81MmjSJtLQ0vL29GTZsGG+//fYl9+Xr68tXX33FnDlzKC0tJSoqis8//5yOHTsC8PLLLxMUFMT8+fM5fvw4vr6+dOvWjRdffBGAsLAwfv75Z5577jmGDh2K0WgkMjKSYcOGXfKHhhBNgaKqquroIIQQ18eECRPIzc3l66+/dnQoQogakp+gQgghhBOTRC2EEEI4Men6FkIIIZyYtKiFEEIIJyaJWgghhHBikqiFEEIIJyaJusJ7771Hq1atcHV1pXv37nZTEDZV27dvZ8SIEYSFhaEoSrVTdlRVZc6cOYSFheHm5saAAQM4cuSIXRmj0ciUKVMIDAzEw8ODP/zhD6SlpdmVycnJYdy4cfj4+ODj48O4cePIzc1t4HdXv+bPn0+PHj3w8vIiKCiIkSNHkpycbFdG6qvK4sWLiYmJwdvbG29vb+Li4vj+++9tz0tdXd78+fNRFIVp06bZ1kl9VZkzZw6KotgtISEhtuebZF05ajYQZ7JixQrVxcVFXbp0qZqYmKg+9dRTqoeHh3rq1ClHh9ag1q1bp86YMUNdvXq1Cqhr1qyxe/71119Xvby81NWrV6sJCQnq/fffr4aGhtrNfDRx4kS1efPm6saNG9X9+/ert912m9q5c2fVZDLZygwbNkzt1KmTumPHDnXHjh1qp06d1Lvuuut6vc16MXToUHXZsmXq4cOH1fj4ePXOO+9UIyIi1MLCQlsZqa8qa9euVb/77js1OTlZTU5OVl988UXVxcVFPXz4sKqqUleXs3v3brVly5ZqTEyMbQYzVZX6utDs2bPVjh07qunp6bYlKyvL9nxTrCtJ1Kqq9uzZU504caLduvbt26vPP/+8gyK6/i5O1BaLRQ0JCVFff/1127rS0lLVx8dH/fe//62qqqrm5uaqLi4u6ooVK2xlTp8+rWo0GnX9+vWqqqpqYmKiCqi7du2yldm5c6cKqEePHm3gd9VwKqed3LZtm6qqUl814efnp37wwQdSV5dRUFCgRkVFqRs3brSbalTqy97s2bPVzp07X/K5plpXN3zXd1lZGfv27WPIkCF264cMGWKb3ehGdOLECTIyMuzqxWAwcOutt9rqZd++fZSXl9uVCQsLo1OnTrYyO3fuxMfHh169etnK9O7dGx8fn0Zdv3l5eUDV1JVSX5dnNptZsWIFRUVFxMXFSV1dxqRJk7jzzjsZNGiQ3Xqpr+qOHTtGWFgYrVq14oEHHuD48eNA062rG/5a39nZ2ZjNZttcvpWCg4OrTapwI6l875eql1OnTtnK6PV6/Pz8qpWp3D4jI4OgoKBq+w8KCmq09auqKtOnT6dfv362uaGlvqpLSEggLi6O0tJSPD09WbNmDR06dLB90UldVVmxYgX79+9nz5491Z6Tz5a9Xr168fHHH9O2bVsyMzN55ZVX6NOnD0eOHGmydXXDJ+pKF8/Fq6rqJefnvdHUpV4uLnOp8o25fidPnsyhQ4cuOfWk1FeVdu3aER8fT25uLqtXr2b8+PFs27bN9rzUlVVqaipPPfUUGzZswNXV9bLlpL6shg8fbrsfHR1NXFwcN910Ex999BG9e/cGml5d3fBd34GBgWi12mq/krKysqr9KruRVI6ivFK9hISEUFZWRk5OzhXLZGZmVtv/2bNnG2X9TpkyhbVr17Jlyxa7+ZulvqrT6/W0adOG2NhY5s+fT+fOnXnnnXekri6yb98+srKy6N69OzqdDp1Ox7Zt23j33XfR6XS29yL1dWkeHh5ER0dz7NixJvvZuuETtV6vp3v37mzcuNFu/caNG+nTp4+DonK8Vq1aERISYlcvZWVlbNu2zVYv3bt3x8XFxa5Meno6hw8ftpWJi4sjLy+P3bt328r88ssv5OXlNar6VVWVyZMn89VXX/HDDz/QqlUru+elvq5OVVWMRqPU1UUGDhxIQkIC8fHxtiU2NpaxY8cSHx9P69atpb6uwGg0kpSURGhoaNP9bF3nwWtOqfL0rP/85z9qYmKiOm3aNNXDw0M9efKko0NrUAUFBeqBAwfUAwcOqID61ltvqQcOHLCdlvb666+rPj4+6ldffaUmJCSoY8aMueRpDuHh4eqmTZvU/fv3q7fffvslT3OIiYlRd+7cqe7cuVONjo5udKeEPPHEE6qPj4+6detWu9NCiouLbWWkvqq88MIL6vbt29UTJ06ohw4dUl988UVVo9GoGzZsUFVV6upqLhz1rapSXxd6+umn1a1bt6rHjx9Xd+3apd51112ql5eX7fu6KdaVJOoK//rXv9TIyEhVr9er3bp1s51205Rt2bJFBaot48ePV1XVeqrD7Nmz1ZCQENVgMKj9+/dXExIS7PZRUlKiTp48WfX391fd3NzUu+66S01JSbErc+7cOXXs2LGql5eX6uXlpY4dO1bNycm5Tu+yflyqngB12bJltjJSX1Uefvhh2/9Ts2bN1IEDB9qStKpKXV3NxYla6qtK5XnRLi4ualhYmDpq1Cj1yJEjtuebYl3J7FlCCCGEE7vhj1ELIYQQzkwStRBCCOHEJFELIYQQTkwStRBCCOHEJFELIYQQTkwStRBCCOHEJFFfwGg0MmfOHIxGo6NDcXpSV7Uj9VVzUle1I/VVc421rpzmPOr58+fz4osv8tRTT7Fw4UKHxJCfn4+Pjw95eXl4e3s7JIbGQuqqdqS+ak7qqnakvmqusdaVU7So9+zZw5IlS4iJiXF0KEIIIYRTcXiiLiwsZOzYsSxdurTa/KBCCCHEjc7h81FPmjSJO++8k0GDBvHKK6/UaluTycSBAwcIDg5Go7n23xwFBQUAnD59mvz8/GveX1MmdVU7Ul81J3VVO1JfNedMdWWxWMjMzKRr167odFdOxQ5N1CtWrGD//v3s2bOnRuWNRqPdIIB9+/Zx++2313tcHTp0qPd9NlVSV7Uj9VVzUle1I/VVc85UV7t376ZHjx5XLOOwRJ2amspTTz3Fhg0bcHV1rdE28+fPZ+7cudXW7969m9DQ0PoOUQghhGgQ6enp9OzZk+Dg4KuWddio76+//pp77rkHrVZrW2c2m1EUBY1Gg9FotHsOqreoT58+TYcOHUhNTSU8PPy6xS6EEEJci7S0NFq0aFGj/OWwFvXAgQNJSEiwW/fQQw/Rvn17nnvuuWpJGsBgMGAwGGyPHX2MQQghhGhoDkvUXl5edOrUyW6dh4cHAQEB1dYLIYQQNyqHn54lhBBCiMtz+OlZF9q6daujQxBC3ODMZjPl5eWODkM0ci4uLpc8hFsXTpWoHanIaOJgai4mi0r/ts0cHY4Q4jpTVZWMjAxyc3MdHYpoInx9fQkJCUFRlGvajyTqCpuPZjH18wPEhPtIohbiBlSZpIOCgnB3d7/mL1dx41JVleLiYrKysgCu+fRhSdQVurbwBSApPZ/ScjOuLvXTZSGEcH5ms9mWpAMCAhwdjmgC3NzcAMjKyiIoKOiausFlMFmFcD83Ajz0lJtVjpyR076EuJFUHpN2d3d3cCSiKan8PF3rmAdJ1BUURaFLRas6PjXXobEIIRxDurtFfaqvz5Mk6gt0jfAF4EBKjmMDEUIIISpIor5AlxbWaTalRS2EuJENGDCAadOm1bj8yZMnURSF+Pj4BosJrKfwKopyw43Ml8FkF4hp4YOiQFpOCdmFRgI9DVffSAghHORqXavjx49n+fLltd7vV199hYuLS43Lt2jRgvT0dAIDA2v9WuLqJFFfwNvVhZuaefJbViHxKbkM6nD1WU2EEMJR0tPTbfdXrlzJrFmzSE5Otq2rHHlcqby8vEYJ2N/fv1ZxaLVaQkJCarWNqDnp+r6IDCgTQjQWISEhtsXHxwdFUWyPS0tL8fX15YsvvmDAgAG4urryySefcO7cOcaMGUN4eDju7u5ER0fz+eef2+334q7vli1b8tprr/Hwww/j5eVFREQES5YssT1/cdd3ZRf15s2biY2Nxd3dnT59+tj9iAB45ZVXCAoKwsvLi0cffZTnn3+eLl261KoOVq9eTceOHTEYDLRs2ZIFCxbYPf/ee+8RFRWFq6srwcHB3HfffbbnvvzyS6Kjo3FzcyMgIIBBgwZRVFRUq9e/HiRRX0QStRACKi5aUWZyyFKfsw8/99xzTJ06laSkJIYOHUppaSndu3fn22+/5fDhwzz++OOMGzeOX3755Yr7WbBgAbGxsRw4cIAnn3ySJ554gqNHj15xmxkzZrBgwQL27t2LTqfj4Ycftj336aef8uqrr/LGG2+wb98+IiIiWLx4ca3e2759+xg9ejQPPPAACQkJzJkzh5kzZ9q6+/fu3cvUqVOZN28eycnJrF+/nv79+wPW3ogxY8bw8MMPk5SUxNatWxk1alS91n19ka7vi1Qm6oOpuVgsKhqNnK4hxI2opNxMh1n/c8hrJ84biru+fr6ep02bxqhRo+zWPfPMM7b7U6ZMYf369axatYpevXpddj933HEHTz75JGBN/m+//TZbt26lffv2l93m1Vdf5dZbbwXg+eef584776S0tBRXV1f++c9/8sgjj/DQQw8BMGvWLDZs2EBhYWGN39tbb73FwIEDmTlzJgBt27YlMTGRN998kwkTJpCSkoKHhwd33XUXXl5eREZG0rVrV8CaqE0mE6NGjSIyMhKA6OjoGr/29SQt6ou0D/HC1UVDgdHE8eyaf2CEEMIZxcbG2j02m828+uqrxMTEEBAQgKenJxs2bCAlJeWK+4mJibHdr+xir7xEZk22qbyMZuU2ycnJ9OzZ0678xY+vJikpib59+9qt69u3L8eOHcNsNjN48GAiIyNp3bo148aN49NPP6W4uBiAzp07M3DgQKKjo/njH//I0qVLyclxzlNzpUV9EZ1WQ3RzH/aczOFASi5tgrwcHZIQwgHcXLQkzhvqsNeuLx4eHnaPFyxYwNtvv83ChQuJjo7Gw8ODadOmUVZWdsX9XDwITVEULBZLjbepHKF+4TYXj1qvbbezqqpX3IeXlxf79+9n69atbNiwgVmzZjFnzhz27NmDr68vGzduZMeOHWzYsIF//vOfzJgxg19++YVWrVrVKo6GJi3qS5Dj1EIIRVFw1+scsjTkFdJ+/PFH7r77bv785z/TuXNnWrduzbFjxxrs9S6nXbt27N69227d3r17a7WPDh068NNPP9mt27FjB23btrVdW1un0zFo0CD+/ve/c+jQIU6ePMkPP/wAWP/Gffv2Ze7cuRw4cAC9Xs+aNWuu4V01DGlRX4L1wicnJFELIZqcNm3asHr1anbs2IGfnx9vvfUWGRkZ3Hzzzdc1jilTpvDYY48RGxtLnz59WLlyJYcOHaJ169Y13sfTTz9Njx49ePnll7n//vvZuXMnixYt4r333gPg22+/5fjx4/Tv3x8/Pz/WrVuHxWKhXbt2/PLLL2zevJkhQ4YQFBTEL7/8wtmzZ697PdSEJOpLqLyU6NGMAkrKzLjpZSYtIUTTMHPmTE6cOMHQoUNxd3fn8ccfZ+TIkeTl5V3XOMaOHcvx48d55plnKC0tZfTo0UyYMKFaK/tKunXrxhdffMGsWbN4+eWXCQ0NZd68eUyYMAGwzgf91VdfMWfOHEpLS4mKiuLzzz+nY8eOJCUlsX37dhYuXEh+fj6RkZEsWLCA4cOHN9A7rjtFdcax6DWUlpZGixYtSE1NJTw8/Np2ZjJC6i+Q/Stq7CP0em0zWQVGvvhLHD1b1e7kfyFE41JaWsqJEydo1aoVrq6ujg7nhjV48GBCQkL473//6+hQ6sWVPle1yV/Soq5UkgMfjQAUlOg/0qWFLxsSM4lPzZFELYQQ9ay4uJh///vfDB06FK1Wy+eff86mTZvYuHGjo0NzOjKYrJJXCPi1AlRI3U2Xiu5vOU4thBD1T1EU1q1bxy233EL37t355ptvWL16NYMGDXJ0aE5HWtQXiuwDOSfg1A66tLKeFB+fkuvYmIQQoglyc3Nj06ZNjg6jUZAW9YUi4qy3KTuJCfdFUeBMXilZ+aWOjUsIIcQNSxL1hSL7WG9P78NTY6JtxcVODkj3txBCCAeRRH0h/9bgEQTmMjizXy58IoQQwuEkUV9IUSCyqvvbNqBMjlMLIYRwEEnUF4uo6P4+tdPWoj6UlovZ0mhPNxdCCNGISaK+WERv623qL7Rt5o67XktRmZnfsmQmLSGEENefJOqLhUSD3guM+WjPJhIT7gNAfKpzTn8mhBDXasCAAUybNs32uGXLlixcuPCK2yiKwtdff33Nr11f+7mSOXPm0KVLlwZ9jYYkifpiGi20qJgTNWVnxQQdcECOUwshnMyIESMue4GQnTt3oigK+/fvr/V+9+zZw+OPP36t4dm5XLJMT093yutrOxNJ1JdSOaDs1A4Z+S2EcFqPPPIIP/zwA6dOnar23IcffkiXLl3o1q1brffbrFkz3N3d6yPEqwoJCcFgMFyX12qsJFFfSsv+0Ko/RPS2zaT1a2YBRUaTY+MSQogL3HXXXQQFBbF8+XK79cXFxaxcuZJHHnmEc+fOMWbMGMLDw3F3dyc6OprPP//8ivu9uOv72LFj9O/fH1dXVzp06HDJ63E/99xztG3bFnd3d1q3bs3MmTMpLy8HYPny5cydO5eDBw+iKAqKothivrjrOyEhgdtvvx03NzcCAgJ4/PHHKSysGiM0YcIERo4cyT/+8Q9CQ0MJCAhg0qRJtteqCYvFwrx58wgPD8dgMNClSxfWr19ve76srIzJkycTGhqKq6srLVu2ZP78+bbn58yZQ0REBAaDgbCwMKZOnVrj164LuYTopUT0gvHfABAMhPq4kp5XyqG0POJuCnBsbEKI66usqPbbaA2grfh6NZvAbARFAy5uV9+v3qPGL6PT6XjwwQdZvnw5s2bNQlEUAFatWkVZWRljx46luLiY7t2789xzz+Ht7c13333HuHHjaN26Nb169brqa1gsFkaNGkVgYCC7du0iPz/f7nh2JS8vL5YvX05YWBgJCQk89thjeHl58eyzz3L//fdz+PBh1q9fb7tsqI+PT7V9FBcXM2zYMHr37s2ePXvIysri0UcfZfLkyXY/RrZs2UJoaChbtmzht99+4/7776dLly489thjNaq3d955hwULFvD+++/TtWtXPvzwQ/7whz9w5MgRoqKiePfdd1m7di1ffPEFERERpKamkpqaCsCXX37J22+/zYoVK+jYsSMZGRkcPHiwRq9bV5Koa6BLC1/S8zKIT82VRC3Ejea1sNpv88fl0PEe6/2j38CqCRDZDx76rqrMwmgoPld92zm1mxf64Ycf5s0332Tr1q3cdtttgLXbe9SoUfj5+eHn58czzzxjKz9lyhTWr1/PqlWrapSoN23aRFJSEidPnrRNx/jaa69VO6780ksv2e63bNmSp59+mpUrV/Lss8/i5uaGp6cnOp2OkJCQy77Wp59+SklJCR9//DEeHtYfLIsWLWLEiBG88cYbBAcHA+Dn58eiRYvQarW0b9+eO++8k82bN9c4Uf/jH//gueee44EHHgDgjTfeYMuWLSxcuJB//etfpKSkEBUVRb9+/VAUhcjISNu2KSkphISEMGjQIFxcXIiIiKBnz541et26kq7vKynKhvSDFxynlpHfQgjn0r59e/r06cOHH34IwO+//86PP/7Iww8/DIDZbObVV18lJiaGgIAAPD092bBhAykpKTXaf1JSEhEREXZzJsfFxVUr9+WXX9KvXz9CQkLw9PRk5syZNX6NC1+rc+fOtiQN0LdvXywWC8nJybZ1HTt2RKvV2h6HhoaSlZVVo9fIz8/nzJkz9O3b12593759SUpKAqzd6/Hx8bRr146pU6eyYcMGW7k//vGPlJSU0Lp1ax577DHWrFmDydSwh0Ud2qJevHgxixcv5uTJk4C18mfNmuUcIwBPbLfOT+1/E13ush6PkQFlQtyAXjxT+220FwyOaj/Cug/lonbRtIRri+sCjzzyCJMnT+Zf//oXy5YtIzIykoEDBwKwYMEC3n77bRYuXEh0dDQeHh5MmzaNsrKyGu1bVatf7Kmyi73Srl27eOCBB5g7dy5Dhw7Fx8eHFStWsGDBglq9D1VVq+37Uq/p4uJS7TmLxVKr17r4dS587W7dunHixAm+//57Nm3axOjRoxk0aBBffvklLVq0IDk5mY0bN7Jp0yaefPJJ3nzzTbZt21Ytrvri0BZ1eHg4r7/+Onv37mXv3r3cfvvt3H333Rw5csSRYVmFxFj/sbR6ooNd0GoUMvONpOeVODoyIcT1pPeo/aK9oA2k1VnXXXh8+kr7rYPRo0ej1Wr57LPP+Oijj3jooYdsSefHH3/k7rvv5s9//jOdO3emdevWHDt2rMb77tChAykpKZw5U/WDZefOnXZlfv75ZyIjI5kxYwaxsbFERUVVG4mu1+sxm81Xfa34+HiKiqqO3//8889oNBratm1b45ivxNvbm7CwMH766Se79Tt27ODmm2+2K3f//fezdOlSVq5cyerVqzl//jxgnaLzD3/4A++++y5bt25l586dJCTU3w+vizm0RT1ixAi7x6+++iqLFy9m165ddOzY0UFRVXDzhWdPgJsv7kDbYC+S0vOJT8klNNrtalsLIcR14+npyf3338+LL75IXl4eEyZMsD3Xpk0bVq9ezY4dO/Dz8+Ott94iIyPDLildyaBBg2jXrh0PPvggCxYsID8/nxkzZtiVadOmDSkpKaxYsYIePXrw3XffsWbNGrsyLVu25MSJE8THxxMeHo6Xl1e107LGjh3L7NmzGT9+PHPmzOHs2bNMmTKFcePG2Y5P14e//e1vzJ49m5tuuokuXbqwbNky4uPj+fTTTwF4++23CQ0NpUuXLmg0GlatWkVISAi+vr4sX74cs9lMr169cHd357///S9ubm52x7Hrm9McozabzaxYsYKioqJLHv8AMBqN5Ofn25aCgoKGDcrN13ZXzqcWQjizRx55hJycHAYNGkRERIRt/cyZM+nWrRtDhw5lwIABhISEMHLkyBrvV6PRsGbNGoxGIz179uTRRx/l1VdftStz991389e//pXJkyfTpUsXduzYwcyZM+3K3HvvvQwbNozbbruNZs2aXfIUMXd3d/73v/9x/vx5evTowX333cfAgQNZtGhR7SrjKqZOncrTTz/N008/TXR0NOvXr2ft2rVERUUB1h8+b7zxBrGxsfTo0YOTJ0+ybt06NBoNvr6+LF26lL59+xITE8PmzZv55ptvCAhouIHGinqpAxDXUUJCAnFxcZSWluLp6clnn33GHXfcccmyc+bMYe7cudXWp6am2g10qHdmE18cSOfZLw/Rs5U/X/zl0j8khBCNU2lpKSdOnKBVq1a4uro6OhzRRFzpc5WWlkaLFi1qlL8c3qJu164d8fHx7Nq1iyeeeILx48eTmJh4ybIvvPACeXl5tuVy5epNeQksvwveiKR7sHWEYUJaHiZz7QYtCCGEEHXl8POo9Xo9bdq0ASA2NpY9e/bwzjvv8P7771crazAY7I5p5OfnN2xwLm6QlwplhbQqOYKXQUeB0URyZgEdw6qfrC+EEELUN4e3qC+mqipGo9HRYVSpmJ9ak7qTmBaVM2nlOjAgIYQQNxKHJuoXX3yRH3/8kZMnT5KQkMCMGTPYunUrY8eOdWRY9irnpz61s2pAmcykJYQQ4jpxaNd3ZmYm48aNIz09HR8fH2JiYli/fj2DBw92ZFj2Iq0tak7vo2sP6zmO0qIWQghxvTg0Uf/nP/9x5MvXTEAb8GgGRWfprjsOwG9nCykoLcfLtWGuQiOEcIzaXt1KiCupr8+TwweTOT1FsXZ/J32DX/Zemvt25XRuCYfS8ujbJtDR0Qkh6oFer0ej0XDmzBmaNWuGXq+/7KUshbgaVVUpKyvj7NmzaDQa9Hr9Ne1PEnVNRPSBpG8gZRddIm7jdG4J8am5kqiFaCI0Gg2tWrUiPT3d7lKZQlwLd3d3IiIi0GiubTiYJOqaiKy4wEnKL3Tr68V3h9I5IAPKhGhS9Ho9ERERmEymq16TWoir0Wq16HS6eumZkURdE8HRoPcEYx69PTMB64CyK830IoRofBRFwcXFpcFmQRKiLpzuPGqnpNVBC+vE4G1LD6PTKGQXGjmdKzNpCSGEaFiSqGuq4sInLqd3cXOoNyCnaQkhhGh4kqhrqvI4ddo+24VP5Di1EEKIhiaJuqaax8L4b2HSLzLlpRBCiOtGBpPVlIsrtLoFgC4R1pPYD5/Oo9xswUUrv3eEEEI0DMkwddAqwANvVx1Gk4Wj6QWODkcIIUQTJom6Ngoy4fvn0HzxZzrbur9zHBuTEEKIJk0SdW3o9PDL+3D0W/oGWy+IcECOUwshhGhAcoy6Ntz84LYZENCam9UQ+ClHBpQJIYRoUJKoa+vWvwHQqdAIJHH8bBF5xeX4uMuVjIQQQtQ/6fquowBPAxH+7gAcTMt1bDBCCCGaLEnUtaWqcGon/LiA3s2trWjp/hZCCNFQJFHXlqLAmsdh8zwGep4CJFELIYRoOJKo66Liut+dLUlA1UxaQgghRH2TRF0XFdf9DsrZj16r4XxRGSnnix0clBBCiKZIEnVdVLSoNWf2ER3qBkj3txBCiIYhibouAqPAPRBMpdzhnwHITFpCCCEahiTqulAUiOgNQG9dMiAtaiGEEA1DEnVdRVq7v1sVHQIg8Uw+RpPZkREJIYRogiRR11WEdUCZW+Ye/N20lJktJMlMWkIIIeqZJOq6CokBFw+U0jzuCMkFID5FZtISQghRvyRR15VWBy16AHC722+AHKcWQghR/yRRX4uK07Q6mRIBSdRCCCHqnyTqa1Fx4ZPA8/sAlZPniskpKnNsTEIIIZoUSdTXonkstLwFTdextA0wABAvM2kJIYSoR5Kor4XeHSZ8CwNn0SmiGSAXPhFCCFG/6pSoU1NTSUtLsz3evXs306ZNY8mSJfUWWGPTJcIXkOPUQggh6ledEvWf/vQntmzZAkBGRgaDBw9m9+7dvPjii8ybN69eA2wUSnLpqz0CwEGZSUsIIUQ9qlOiPnz4MD179gTgiy++oFOnTuzYsYPPPvuM5cuX12d8zq80H/7empvW/YkQXQF5JeWcyC5ydFRCCCGaiDol6vLycgwG6+CpTZs28Yc//AGA9u3bk56eXuP9zJ8/nx49euDl5UVQUBAjR44kOTm5LiE5jqs3NGsH/jfRr5kRkO5vIYQQ9adOibpjx478+9//5scff2Tjxo0MGzYMgDNnzhAQEFDj/Wzbto1Jkyaxa9cuNm7ciMlkYsiQIRQVNbIW6aObYep+vFtbL4AiiVoIIUR90dVlozfeeIN77rmHN998k/Hjx9O5c2cA1q5da+sSr4n169fbPV62bBlBQUHs27eP/v371yU0x9C7AxUDyn6WRC2EEKL+1ClRDxgwgOzsbPLz8/Hz87Otf/zxx3F3d69zMHl5eQD4+/vXeR+O1LW5J1rMJKXnU1puxtVF6+iQhBBCNHJ16vouKSnBaDTakvSpU6dYuHAhycnJBAUF1SkQVVWZPn06/fr1o1OnTpcsYzQayc/Pty0FBU40W9XXkwhfcjPD3H+l3Kxy5Ey+oyMSQgjRBNQpUd999918/PHHAOTm5tKrVy8WLFjAyJEjWbx4cZ0CmTx5MocOHeLzzz+/bJn58+fj4+NjWzp06FCn12oQlnKUskKGeZ8ApPtbCCFE/ahTot6/fz+33HILAF9++SXBwcGcOnWKjz/+mHfffbfW+5syZQpr165ly5YthIeHX7bcCy+8QF5enm1JTEysS/gNI6I3AF3VJEAStRBCiPpRp2PUxcXFeHl5AbBhwwZGjRqFRqOhd+/enDp1qsb7UVWVKVOmsGbNGrZu3UqrVq2uWN5gMNhOCwPIz3ei7uWKmbRCCw/jgokDMje1EEKIelCnFnWbNm34+uuvSU1N5X//+x9DhgwBICsrC29v7xrvZ9KkSXzyySd89tlneHl5kZGRQUZGBiUlJXUJy7GatQM3f7RmI9Ga46TllJBdaHR0VEIIIRq5OiXqWbNm8cwzz9CyZUt69uxJXJx1uscNGzbQtWvXGu9n8eLF5OXlMWDAAEJDQ23LypUr6xKWYykKRFjrYZhXxXFqmaBDCCHENapT1/d9991Hv379SE9Pt51DDTBw4EDuueeeGu+nyV0TOzIOkr+jr/4YMJT41FwGdQh2dFRCCCEasTolaoCQkBBCQkJIS0tDURSaN29eq4udNEkVx6nblB5GwSIDyoQQQlyzOnV9WywW5s2bh4+PD5GRkURERODr68vLL7+MxWKp7xgbj9AYcHHHUJ5PlHKag6m5WCxNrNdACCHEdVWnRD1jxgwWLVrE66+/zoEDB9i/fz+vvfYa//znP5k5c2Z9x9h4aF0g3Hq97z4uyRQYTRzPLnRwUEIIIRqzOnV9f/TRR3zwwQe2WbMAOnfuTPPmzXnyySd59dVX6y3ARieyD5zYxiD34ywvgwMpubQJ8nJ0VEIIIRqpOrWoz58/T/v27autb9++PefPn7/moBq1ipHfMZZEQJXj1EIIIa5JnRJ1586dWbRoUbX1ixYtIiYm5pqDatTCe4BGh2f5OYLIlUQthBDimtSp6/vvf/87d955J5s2bSIuLg5FUdixYwepqamsW7euvmNsXPTu8NB6Mg0tyXprN+cyCigpM+Oml5m0hBBC1F6dWtS33norv/76K/fccw+5ubmcP3+eUaNGceTIEZYtW1bfMTY+LXoQ0iyQIC8DZovK4TN5jo5ICCFEI1Xn86jDwsKqDRo7ePAgH330ER9++OE1B9bYKYpClxa+bEjM5EBKDj1aNs45toUQQjhWnVrU4iosFtgwk3lnn8KPfDlOLYQQos4kUTcEjQaObSCk4DA9NMlyzW8hhBB1Vueub3EVtzxNabmJ/V9Cdl4pWfmlBHm7OjoqIYQQjUytEvWoUaOu+Hxubu61xNK0xIzGFQjYvp3szAIOpOYytGOIo6MSQgjRyNQqUfv4+Fz1+QcffPCaAmpqurTwJTmzgHhJ1EIIIeqgVolaTr2qpfRDPGD6mgQlgPiUAEdHI4QQohGSwWQNace7dD26gCHavRxKy8UsM2kJIYSoJUnUDaniut+9tb9SVGbmtyyZSUsIIUTtSKJuSJF9AOiiOYYOE/GpOQ4OSAghRGMjibohBbYDNz9cVSOdlJNy4RMhhBC1Jom6IWk0tu7vHpqjHJALnwghhKglSdQNrSJR99Qk82tmAUVGk4MDEkII0ZhIom5oFcepe2qTUVULh9JkJi0hhBA1J4m6oYXEgM4NHwppo5yR49RCCCFqRRJ1Q9PpITwWgJ6aozLyWwghRK1Ior4eKrq/e2iOSotaCCFErUiivh5sI79/JTPfSHpeiYMDEkII0VhIor4ewnuAoqW5kk0Y2TI/tRBCiBqTRH09GDyhy5/Y3mwMFhTp/hZCCFFjtZo9S1yDuxeRsTeVjNRDHJBELYQQooakRX0ddW3hC0BCWh4ms8WxwQghhGgUJFFfRzd5qwwxHEFXXsCvmTKTlhBCiKuTRH0daZYNZYnyKr01iRyQ86mFEELUgCTq66lFT3INobhRJiO/hRBC1IhDE/X27dsZMWIEYWFhKIrC119/7chwGt7wN9lz9zbWWvrIyG8hhBA14tBEXVRUROfOnVm0aJEjw7h+dHq6VAwo++1sIQWl5Y6NRwghhNNz6OlZw4cPZ/jw4Y4M4bpr5mUg3MdAdl4+h9Ly6Nsm0NEhCSGEcGJyjPp6+/kdNpQ/yF+030r3txBCiKtqVBc8MRqNGI1G2+OCggIHRlNHeg/cLUX00BxluQwoE0IIcRWNqkU9f/58fHx8bEuHDh0cHVLtRVhn0uqm+Y2ElGxUVXVwQEIIIZxZo0rUL7zwAnl5ebYlMTHR0SHVXrP2qK6+uCtGQoqTOZ0rM2kJIYS4vEaVqA0GA97e3rbFy8vL0SHVnkaDEtEbgB6aZDlOLYQQ4oocmqgLCwuJj48nPj4egBMnThAfH09KSoojw2p4tvmpk+XCJ0IIIa7IoYl67969dO3ala5duwIwffp0unbtyqxZsxwZVsOLtB6njtUkcyBFLiUqhBDi8hw66nvAgAE35mCq0C5YdK4EmAooPpNEuTkOF22jOgohhBDiOpHs4Ag6PUrzWAC6qIkcTW+Ep5kJIYS4LiRRO4hS0f1tHVAm3d9CCCEuTRK1o0RaB5T11BzlgIz8FkIIcRmSqB0lvCcWRUu4ks3pU8ccHY0QQggnJYnaUQyeWIKjsagKHjlHySuWmbSEEEJUJ4nagXT3LmWEx3/5wdKNg2m5jg5HCCGEE5JE7UjN2tImIhxArlAmhBDikiRRO1iXFr6AJGohhBCXJonawQYVfM0X+rm4p/xwY178RQghxBVJonawMONxemqS6VR2iNTzMpOWEEIIew69hKgAbdexvHvMny/OtSI0NYeIAHdHhySEEMKJSIva0SJ6c77taNLUZhyQmbSEEEJcRBK1E5ABZUIIIS5HErUTiPXO5SHt97RI34DRZHZ0OEIIIZyIJGon0PzcDma7/JfRyiaSZCYtIYQQF5BE7QQqZ9LqpjnGwZNnHRyNEEIIZyKJ2hk0u5lSnTceipHs3/Y6OhohhBBORBK1M9BoKArqDoBr+i8ODkYIIYQzkUTtJNyjbgHgppLD5BSVOTgaIYQQzkIStZNwu6kfALGaZOJTcxwcjRBCCGchidpZhHWlXNETqOTz7sp1vPxtIr9myghwIYS40cklRJ2FTk9pcFdcMn7hGdNSfty5i1d3RKIJiWZorxju6tIcT4P8uYQQ4kYj3/xOxKvTcMj4hb7aI/TVHgGg5Jyejms+ZN53SdwZHcqjEem0jQhDadYedHoHRyyEEKKhSaJ2Jn2mQkgMpMdDxmFM6QnkmdxoqXpx/GwRq/al8VjC31A0p/k+5h16DBlDoKcBsn+DvBQIjgbPZo5+F0IIIeqRJGpnotFCm4HWBesfJ8RiZrOiYe+pHL7YfYpzR/zIV3OYu1tD9t7NDLo5mOddV9PyyL+s+/AMhuBOENLJehvcCQKjQOviuPclhBCNVVkRZCRAWSG0GeSQECRROzuNFgXo0dKfHi39KSjdyrcHzxC8J5WMtDzWH8kgUnuesfpQWqgZKIWZUJgJv2+u2odWD83aQ0g0BHesSOTR4O7vsLclhBBOw1wO50/AuWOQfQzCe0DLvtbnzsTD8jvANxKmHXJIeJKoGxkvVxfG9IpkTK9IkjMKWLknlZUHRvF+8QjcKKW9ksqdwecZ6JdFZPlxNFmJUFYAGYesS6V2d8KYz6z3VRUS/w+COkBAG9DIyQBCiCao6FxFMv7VmpCzj1kf55wEi6mqXJ8pVYk6MAq8w63fjRaLQ74fJVE3Yu1CvJg1ogPPDW/HxsRMVu5J5affXDmQAa9kgI+bC/d0DmFse4Uo9SRkHIbMw9ZunJDoqh3ln4ZV40HRwox00Bis60/vA4M3+N8kyVsI0TiYTaC9ILVtexN+22hNziVXuEaFiwcEtoGAKAjtUrXeMwimH2mwcGtCEnUTYNBpuSsmjLtiwkjLKWbV3jS+3JfG6dwSlu9KZfkuiG7ux+gef+IPd4fh4+ZibUVXKs2zdvWoKugMVevX/a0iWftA867QvDs0j7XeegVf/zcqhBBg/a4qPgemUvAJt64rOgf/GQwF6fB8alWyzk6G1AsuzezTwtpKDoiy3lbe9w4DRbn+76UGFFW98Bu7cUlLS6NFixakpqYSHh7u6HCcitmi8vNv2azck8qGxAzKzdY/s0Gn4c7oUEb3aEGvVv4oF34wVbXqg6qq8PEfIHW39Z/hYt7h0LwbhFck7tAuYPBs+DfWlFkskJcKWUmQlWgda+AbCYFtrV8mPi2kZ0PceMqK4cx+a6PhbHJVd3VJDnS8B/643FrOYoHXwsBUAlP2Q8BN1vUnf4bCDGsyDmgDeneHvZUL1SZ/SaK+AZwrNLLmwGm+2JvKr5mFtvUtA9wZ3aMF93ULJ8jb9dIbm8utSeP0voplvzWRcNHHRtFYB6wNmw+tBzTYe2kyCs9aD0NUJuWsJDh71Dqy9HKihsLYL6oeJ/4f+LWyji3QNsHOMWMB5KeDagYXN9C5gYsr6D2tZ0iIpkdVIfcUpO6BtN3WlnDGYetnoBrFOgr7z19WrUrba20Ze4U6beu4kiRqcUmqqhKfmsvKPal8c/AMRWXWD79Wo3Bbu2bc3yOC29o1Q6e9SqvNWGAdCXlh8s5PAyBv7HqKmnWhtNyMIWk1Poc/JqvV3aS0foDScgtGkxljxW3pBbel5WaMpqpbHzcX2oZ40T7Ei7bBXtbu+sZIVSFllzUZdxlrTTQAa6fA/o+rl9fqrS3ooJutXzY5J60tiPO/Q+zDMPwNa7mSHHijpfX+C2lg8LLeP/K1tUswsK118Qxy3i8sixlO/mQdI5F32voZyjtd9diYd+nt7vsQOt1rvZ+8Hr57GiLj4N4Pqsp89bi1J6gyuVfeuriDzrUi8V90G3Sz9UseoLwUSnOt5V29G7QaRIX9H8Pml6Eoq/pzXmHQoof1jJWANtYeJv+bnKZ1XBe1yV9N8Ge4uBxFUega4UfXCD9m3tWB7xLSWbknlX2nctiUlMWmpCyaeRm4vV0QAKUVSbXUZL4gkVYl29LyjhhNN1NaPgY/y3k6a46z/T+ZlPEDAK/pvuZPur18ciaU17dZu6G8KeRtl8UctNzEQfUm4i03kcfVu8xDfVxpG1yVuNuFeNEmyBNXFydpWZUVW1vEWUmgWqDbuKrnPn/A+qUf3gNCY6zrgqOtXzhBN1tbxJW3/q0vfc672WTt0qtUmgctelt/NFUmaYC9H8KJbVWPDT4Vx+HaXnDbFvxbXfHcelVVySspp7TcgqerDg+91v4wyZWYjJB/BjwCq2I7vg12Lba+z0Gzq8r+957LtJYq4/cGjc6adMtLANWadG31kGtN8EXZ9tslfw/G/JrFW+mut60/hgBSdsJ/R1r/Jk/urCrzwSDre9MZ7H8E6AxVSV/nWrG+Yrnp9qoRxCU58PsP4Opjf05uzknr5+bifTrrj6xrte1N+PV7GPKq9UcWWH8UFWVZ/96hnSG8J7ToQVFwLCkmP87klqDRKHgadLhbtHjkq3gYjHgYtLi51OLz2QhJor5BeRh0jI5twejYFvyWVcAXe9NYvS+NswVGVu5NrfX+zuLHJot1Tm29VoNBp2Gl7l6OazqR5t6Sjq7eGHQaYs0nGXjuAAO1B2zbnjOEk+HZgSzvTpz3jSbf52YySiA5o4BfMwo4k1dKesWy7deztu00CrQM9KBdReKuvI0M8ECraaB/WlMZnPutqru6sus65yS2wwF+LasStaLATbeBsdD6RVyp1+PWpaa0OtBekJD9WsIj/6terlV/a3LI/tXahWjMg9N7rcsFVEWL0TuSPPeWJDa7g11u/cisqOPM/FIy8kspLa+KV1HA06DDz6AhQp9HpC6X5trzhCrnCLJkE2g5i2/5WbzLMnErOwfA0VvfozzqLrxcdfjnZOH96/dQcr4qCI0WIvtYv5h9mlvHPfg0B+/m1gFC3mH2P0JU1fojQHPB11bUEHjsB+uX/IWGv2G9UEV5sbV1bCq5xG3FYiq1rvMIqtreXG49nKO76JBQQYa1xV8bBs+qRH3+BHz5sPU9Tk+sKvPlw9beqYtVJnuDt7U+Lqyf8B7WcSLOymSE9IPWcS5ZiXD3v6p+eGQmWN9vyk5M4b2s/9+aLuT3/ohDlpacyFNJOV5M6t5izhcdvupLKQp46HV4GLQVtzrc9Vo8DNb7HpX3K27dDTo8DVrc9bqq7S4q63K1nsXryOFd3++99x5vvvkm6enpdOzYkYULF3LLLbfUaFvp+q5fZSYLPxzNIjE9H4POmmwNLlpcL3Hr6qLF4KLBVVd16+qiRa/TXDlJ5qVB0rdV3ebnf69eRqMDzxDrtcx1rpgMvsQP/JSjGQX8mllAx2P/xqfwd5YaB7NPbQdAGyWNu7U7KFN1WDR6fLw88PPxppmvF0G+3oQG+ODr5Yni4gpag3XfWoP1AjCVXx5lxdZbnWvVoK2zyZC4tioxnztmf77lhdwDrC2w4E7WY/UO+IVfWm4mI8+aaLPO51GSeQwl+1cMeb/jXXSS4LIUIiyn8VSqBgi+Uj6WD8x3AtBOSeET/WvEW6J4rPxptBoFs8XCSv3LRChZBJGDVrn6V4ZRdeEl00OsMg8AIIxsBmgPkqqEkWjojJerDk9XHV4GF+utqw4vgw4v16rHngYd3q4u+Li74Oeux8/dBW9XFzQN9SPsYqpq7Z6/8Ph/9jHrOILyUmuCr2zp2+5X/AgwGavWt7+zatxGVpL1bAr3ABj9UdV+l90JZw5Yt73wB92V9PsrDJpjvZ93Gj4aYe0pGftl1WcvIwE0LtYEf+GPnoaQn249ppy2x5qc0+PBXGZ7+ugft/GbOYiU88W4pPxEWW46m4ujOJTvjsly5c+Un7sLzf3crIO9y8wUGk0UG022w3cNQa/V4FGZzCsTuV7Hg3GRDOkYcs37bzRd3ytXrmTatGm899579O3bl/fff5/hw4eTmJhIRESEI0O7Iel1GoZ1CmFYp2v/EF6WTzj0nlj1uPi89QuqMnGn7YXibNsxbwCdewCxLf2JbVlxJbVlJ6BwB71HTeCQT0+SMwow/HqMB9O+vmC/FUv6lcPJ+1sWPh4Vp6T935NwZA0M/zv0+ot13dmjsOUV+430XhVd1Rd1WzfgddZVVSW/xER6fok1EVck44tvc4vLL7F164rFtjfCNLl09zhLtCET/LvzULOWhPq40rUgg2Z78unfHI4+MgyDTkNpuQX9P59DW2BtDVs0LpS6BlHkGkKePohcbTOytYFkKYGcsQSQavHnTJk7BUYzIaUmCkrLOVMWyGdm66VxMZVxrqisWpQ1oVHA112Pr7sL/u56fCsSuL9H1X0/D70tsft56PF1c7n6uItLUZTqg/QCo+oUt03QzTDh2+rrH/qu6r65vHryL82tOHafVnU8P6xr1TZ5qdYfvRaT/Q/Eb6ZV9aa4+lTvtfAJt+/BuPD0zCsxlVlbxam7IXU3aupulAv+Z21hKd7st0Sxx9SGVf89wlkqeyOaVSwAKnqthnB/NyL83Wnh52699a+8dcPL9dKHaSwWlZJyM0VlJoqMZoqMJoqMpqpkXmai0Gi2JfUio6mi7AVljFVli8rMlJmsP5TKzBbKii3kXPQ/NTy6Ab8fL8OhLepevXrRrVs3Fi9ebFt38803M3LkSObPn3/V7aVF3QSpqvVLp+is9cvAVGr94rlwJHnSt9YvrKjBVadgnImH+M+wmIwUFxdTUFhIcUkxpSUlGI0lqOWluFCOHhN6ytErJrRYiDMuIsTblbYhXszIf5l2uds53W8+Abf+BYNOg+ncSZSt8zEFtqM8oD1Gv3YYPcIwWVTKzSomiwWTWaXcbKlYZ8FsUautM1WULTermGzrrffLLReuqypbUmYmI7+UzHwj6Xkldl3RV+LmoiXUx5Vgb1frrY8rId6uhFTchvq4EuBpuHTPR1mx9bxTczm06Fm1/sSP1u5ln+bWLuJaniZmtqgUGk0UGq2Ju7DUREGpiYKLHhcaTeTbPV9ObrF1KTRepiejBrxcdbZk7l/RQvd11+Pv4VKR4PX4eVS23K0/BGoy/kFVrX/HMrMFY7nZ+uVusi7GiqXMZLFbX2a2jvGoXGc02d+Wmc12+ygzWTCrKjqNBr1OQafR4KLV4KJVcNFq0GkVPCkhrORXXJVyzgT2xUVrLTf8wEQC8o6gN9VsbnuTWzMKek6jtNsj1tcoK8A1dRsav0hy/DqRer6YM5lZDFvfHxeL0W5bs6qQrEaw39KG/ZYo9qltOaUGA9bPWZCXwZaAK5NwZSIO9nK9fj0lV1Fmsv7vFZZZW+2FFyX+zuG+tG527aeiNopR32VlZbi7u7Nq1Sruuece2/qnnnqK+Ph4tm3bVm0bo9GI0Vj14Th9+jQdOnSQRC2uqrTczPGzRSRn5pOcUUhyRj6/ZhZyOrdqgJYOEwbKKUdHGc45ytzP3cWWgK2J140QHwMhPm62ZOztqmuSA2uMJjN5xeXkFJdzvqiM3OIycorLySkuI6fogvvFZeRWlMkruVQPQ82467X4uevxdnPBbLkw0VqsZy5UJNrGwIMSQpVzhFUsoco5wrjgvnIOV8VaVy+VP8Qn5sEAxCpH+dIwjxRLM/qXvWPb3xb9X/FTCtlvibIuahS/6toS6B9AuF9lEnYjIsDaQg73c8dN7yQDP51Eo+j6zs7Oxmw2Exxsf4Wr4OBgMjIyLrnN/PnzmTt37vUITzQxri5aOoR50yHM/lSb/NJyjmUWWI9/ZxSQnFlAckYBZZfsQrY27l001laMTlPVorG2chR0Wo3deltZrQYXjXLRfY2t5VO5vwufc3XREOx9QcvY29V5Rrk7gEGnJchbe/lz/i/BZLaQV2JN7rnFZRUJ3prQzxeXkVtUldwry+QUl2O2qBSXmSkuK7H7MXc1Oo2CvmJ8h75y0Wow6LS2x4bKdS7W26r1Wlv5ynKV+9EoCqaKnpeyyp4Ys7WHpvyi+5W9OeUWlXKTBZOlcptwSswWjppVEiq2MVX0BphMFjzMeQRasjij8cMFhXKzigUNeyxtyVT90SgQ6uNGC383/uv9Pv7NwmgR4Mnt/u5M8HcnwEPfJH8gOgOHj/q++A+rqupl/9gvvPAC06dPtz2ubFELUVferi50j/Sne2TVTGKqqtq+rC9Ovg02mlw0CJ1WQ4CngQDPGh57xXrcs8BosiX2/FJT9QR8UYKtTL7O0n1bH1RVxWQZTrl5Cm1NKkf11h8S4vpzWKIODAxEq9VWaz1nZWVVa2VXMhgMGAxV/3D5+bU8T1KIGlAUBX8PvaPDEA6i0Sj4uLng4+ZCZICHo8NxGEVRbMfBkX8Hh3LYzyO9Xk/37t3ZuHGj3fqNGzfSp08fB0UlhBBCOBeHdn1Pnz6dcePGERsbS1xcHEuWLCElJYWJEydefWMhhBDiBuDQRH3//fdz7tw55s2bR3p6Op06dWLdunVERkY6MiwhhBDCaTh8MNmTTz7Jk08+6egwhBBCCKckQ/iEEEIIJ+bwFvW1sFisFxtIT7/KdSKFEEIIJ1KZtyrz2JU06kSdmZkJQM+ePa9SUgghhHA+mZmZV53bwuGzZ10Lk8nEgQMHCA4ORlPLaw9fSkFBAR06dCAxMREvrwaeaaYJkXqrO6m7upF6qzupu7qp73qzWCxkZmbStWtXdLort5kbdaKub/n5+fj4+JCXl4e3t/fVNxCA1Nu1kLqrG6m3upO6qxtH1psMJhNCCCGcmCRqIYQQwolJor6AwWBg9uzZdtcTF1cn9VZ3Und1I/VWd1J3dePIepNj1EIIIYQTkxa1EEII4cQkUQshhBBOTBK1EEII4cQkUVd47733aNWqFa6urnTv3p0ff/zR0SE5ve3btzNixAjCwsJQFIWvv/7a0SE1CvPnz6dHjx54eXkRFBTEyJEjSU5OdnRYjcLixYuJiYnB29sbb29v4uLi+P777x0dVqMzf/58FEVh2rRpjg7F6c2ZMwdFUeyWkJCQ6xqDJGpg5cqVTJs2jRkzZnDgwAFuueUWhg8fTkpKiqNDc2pFRUV07tyZRYsWOTqURmXbtm1MmjSJXbt2sXHjRkwmE0OGDKGoqMjRoTm98PBwXn/9dfbu3cvevXu5/fbbufvuuzly5IijQ2s09uzZw5IlS4iJiXF0KI1Gx44dSU9Pty0JCQnXNwBVqD179lQnTpxot659+/bq888/76CIGh9AXbNmjaPDaJSysrJUQN22bZujQ2mU/Pz81A8++MDRYTQKBQUFalRUlLpx40b11ltvVZ966ilHh+T0Zs+erXbu3NmhMdzwLeqysjL27dvHkCFD7NYPGTKEHTt2OCgqcSPJy8sDwN/f38GRNC5ms5kVK1ZQVFREXFyco8NpFCZNmsSdd97JoEGDHB1Ko3Ls2DHCwsJo1aoVDzzwAMePH7+ur9+oZ8+qD9nZ2ZjNZoKDg+3WBwcHk5GR4aCoxI1CVVWmT59Ov3796NSpk6PDaRQSEhKIi4ujtLQUT09P1qxZQ4cOHRwdltNbsWIF+/fvZ8+ePY4OpVHp1asXH3/8MW3btiUzM5NXXnmFPn36cOTIEQICAq5LDDd8oq6kKIrdY1VVq60Tor5NnjyZQ4cO8dNPPzk6lEajXbt2xMfHk5uby+rVqxk/fjzbtm2TZH0FqampPPXUU2zYsAFXV1dHh9OoDB8+3HY/OjqauLg4brrpJj766COmT59+XWK44RN1YGAgWq22Wus5KyurWitbiPo0ZcoU1q5dy/bt2wkPD3d0OI2GXq+nTZs2AMTGxrJnzx7eeecd3n//fQdH5rz27dtHVlYW3bt3t60zm81s376dRYsWYTQa0Wq1Doyw8fDw8CA6Oppjx45dt9e84Y9R6/V6unfvzsaNG+3Wb9y4kT59+jgoKtGUqarK5MmT+eqrr/jhhx9o1aqVo0Nq1FRVxWg0OjoMpzZw4EASEhKIj4+3LbGxsYwdO5b4+HhJ0rVgNBpJSkoiNDT0ur3mDd+iBpg+fTrjxo0jNjaWuLg4lixZQkpKChMnTnR0aE6tsLCQ3377zfb4xIkTxMfH4+/vT0REhAMjc26TJk3is88+4//+7//w8vKy9eb4+Pjg5ubm4Oic24svvsjw4cNp0aIFBQUFrFixgq1bt7J+/XpHh+bUvLy8qo2B8PDwICAgQMZGXMUzzzzDiBEjiIiIICsri1deeYX8/HzGjx9/3WKQRA3cf//9nDt3jnnz5pGenk6nTp1Yt24dkZGRjg7Nqe3du5fbbrvN9rjyeM348eNZvny5g6JyfosXLwZgwIABduuXLVvGhAkTrn9AjUhmZibjxo0jPT0dHx8fYmJiWL9+PYMHD3Z0aKKJSktLY8yYMWRnZ9OsWTN69+7Nrl27rmt+kNmzhBBCCCd2wx+jFkIIIZyZJGohhBDCiUmiFkIIIZyYJGohhBDCiUmiFkIIIZyYJGohhBDCiUmiFkIIIZyYJGohhBDCiUmiFkJcM0VR+Prrrx0dhhBNkiRqIRq5CRMmoChKtWXYsGGODk0IUQ/kWt9CNAHDhg1j2bJldusMBoODohFC1CdpUQvRBBgMBkJCQuwWPz8/wNotvXjxYoYPH46bmxutWrVi1apVdtsnJCRw++234+bmRkBAAI8//jiFhYV2ZT788EM6duyIwWAgNDSUyZMn2z2fnZ3NPffcg7u7O1FRUaxdu9b2XE5ODmPHjqVZs2a4ubkRFRVV7YeFEOLSJFELcQOYOXMm9957LwcPHuTPf/4zY8aMISkpCYDi4mKGDRuGn58fe/bsYdWqVWzatMkuES9evJhJkybx+OOPk5CQwNq1a2nTpo3da8ydO5fRo0dz6NAh7rjjDsaOHcv58+dtr5+YmMj3339PUlISixcvJjAw8PpVgBCNmSqEaNTGjx+varVa1cPDw26ZN2+eqqqqCqgTJ06026ZXr17qE088oaqqqi5ZskT18/NTCwsLbc9/9913qkajUTMyMlRVVdWwsDB1xowZl40BUF966SXb48LCQlVRFPX7779XVVVVR4wYoT700EP184aFuMHIMWohmoDbbrvNNs91JX9/f9v9uLg4u+fi4uKIj48HICkpic6dO+Ph4WF7vm/fvlgsFpKTk1EUhTNnzjBw4MArxhATE2O77+HhgZeXF1lZWQA88cQT3Hvvvezfv58hQ4YwcuRI+vTpU6f3KsSNRhK1EE2Ah4dHta7oq1EUBQBVVW33L1XGzc2tRvtzcXGptq3FYgFg+PDhnDp1iu+++45NmzYxcOBAJk2axD/+8Y9axSzEjUiOUQtxA9i1a1e1x+3btwegQ4cOxMfHU1RUZHv+559/RqPR0LZtW7y8vGjZsiWbN2++phiaNWvGhAkT+OSTT1i4cCFLliy5pv0JcaOQFrUQTYDRaCQjI8NunU6nsw3YWrVqFbGxsfTr149PP/2U3bt385///AeAsWPHMnv2bMaPH8+cOXM4e/YsU6ZMYdy4cQQHBwMwZ84cJk6cSFBQEMOHD6egoICff/6ZKVOm1Ci+WbNm0b17dzp27IjRaOTbb7/l5ptvrscaEKLpkkQtRBOwfv16QkND7da1a9eOo0ePAtYR2StWrODJJ58kJCSETz/9lA4dOgDg7u7O//73P5566il69OiBu7s79957L2+99ZZtX+PHj6e0tJS3336bZ555hsDAQO67774ax6fX63nhhRc4efIkbm5u3HLLLaxYsaIe3rkQTZ+iqqrq6CCEEA1HURTWrFnDyJEjHR2KEKIO5Bi1EEII4cQkUQshhBBOTI5RC9HEydEtIRo3aVELIYQQTkwStRBCCOHEJFELIYQQTkwStRBCCOHEJFELIYQQTkwStRBCCOHEJFELIYQQTkwStRBCCOHEJFELIYQQTuz/ASC12CZvu1AzAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_values\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses, label=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa074723-e3f7-4f7e-a267-855531a037dc",
   "metadata": {
    "id": "aa074723-e3f7-4f7e-a267-855531a037dc"
   },
   "source": [
    "- Note that we previously calculated the accuracy values on 5 batches only via the `eval_iter=5` setting; below, we calculate the accuracies on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1D2awlEq0gZi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1D2awlEq0gZi",
    "outputId": "d603eda1-d912-43eb-ec9c-af6a622510a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 99.52%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 97.00%\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import calc_accuracy_loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f87f5e6-339e-4fcf-900b-6d845d3c713d",
   "metadata": {
    "id": "1f87f5e6-339e-4fcf-900b-6d845d3c713d"
   },
   "source": [
    "- As we can see based on the relatively high accuracy values above, the LoRA finetuning was successful"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
